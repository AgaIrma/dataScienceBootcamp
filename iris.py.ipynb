{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Iris Dataset (built-in dataset)\n- The dataset contains a set of 150 records under five attributes sepal\nlength, sepal width, petal length, petal width and species.\n\n- This data sets consists of 3 different types of irises’ ( Setosa , Versicolour , and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray.\n\n- The rows being the samples and the columns being: Sepal Length, Sepal Width,\nPetal Length and Petal Width.","metadata":{"id":"NFm-epyeFzLJ"}},{"cell_type":"markdown","source":"# 0.Authors","metadata":{"id":"68C7kdAJGIY1"}},{"cell_type":"markdown","source":"### Sohaila Diab    \n### Osama Ibrahim    \n### Rawan Khaled    \n","metadata":{"id":"1kjRF_n1GN4H"}},{"cell_type":"markdown","source":"# 1. Imports","metadata":{"id":"A1G-mdHaiCWz"}},{"cell_type":"code","source":"import sklearn as sk\nfrom sklearn.datasets import load_iris\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport seaborn as sns\nsns.set( color_codes=True)\n# Evaluation\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import classification_report\nfrom plotly.express import scatter_3d\n\n# Modeling \nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import ComplementNB\nfrom sklearn.naive_bayes import BernoulliNB\n\n\n#decision boundery\nfrom mlxtend.plotting import plot_decision_regions\n","metadata":{"id":"X8lXcaCtFtI6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Load Data","metadata":{"id":"KgYA81kRiFa3"}},{"cell_type":"code","source":"# Function to convert sklearn dataset to dataFrame\n\ndef sklearn_to_df(sklearn_dataset):\n    df = pd.DataFrame(sklearn_dataset.data, columns=sklearn_dataset.feature_names)\n    df['species'] = pd.Series(sklearn_dataset.target) # Changed col name from 'target' to 'species'\n    return df","metadata":{"id":"JzRJ7LZqkU7-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load data from sklearn\niris = sklearn_to_df(sk.datasets.load_iris())\niris.head()","metadata":{"id":"AVQFocPXGbHr","outputId":"05204b61-21db-4f4f-b9d9-48c2d9bc56a9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris.shape","metadata":{"id":"Je2RQ-OaBmT2","outputId":"239952a8-0d27-428f-ec83-44b0681aa1bf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.Understanding the Data","metadata":{"id":"LUEtESqMGwDp"}},{"cell_type":"code","source":"iris.info()","metadata":{"id":"_PNEEDuPG7AG","outputId":"bcfd9139-c142-4acc-e691-823dd85f67b4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris.describe()","metadata":{"id":"8NN4QJ1kG-3M","outputId":"dc54155e-fbb8-44bd-f493-724b19eec3b2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Target Distribution\niris['species'].value_counts().plot(kind='bar')\nplt.title('Target Distribution')\nplt.xlabel('species')\nplt.ylabel('Count')","metadata":{"id":"p-qcbhjsHJkn","outputId":"b98c1944-e232-4a95-948a-9f8137f32ae4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sepal length (cm) Distribution\niris['sepal length (cm)'].plot(kind='hist')\nplt.title('sepal length (cm) Distribution')\nplt.xlabel('sepal length (cm)')\nplt.ylabel('Frequency')","metadata":{"id":"3vQ2qWQtHNlQ","outputId":"4bcfe569-ef5c-4432-817b-3679f0dc6b22"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sepal width (cm) Distribution\niris['sepal width (cm)'].plot(kind='hist')\nplt.title('sepal width (cm) Distribution')\nplt.xlabel('sepal width (cm)')\nplt.ylabel('Frequency')\n","metadata":{"id":"zl0wT9MgHcGJ","outputId":"db30d33c-1097-4b58-a799-aea3a0b43935"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris.plot(kind=\"scatter\", x=\"sepal length (cm)\", y=\"sepal width (cm)\")","metadata":{"id":"Ribua0jWHnjV","outputId":"85d896c9-dd22-494a-bb02-526ae13c9f0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.FacetGrid(iris, hue=\"species\", size=5) \\\n   .map(plt.scatter, \"sepal length (cm)\", \"sepal width (cm)\") \\\n   .add_legend()\n","metadata":{"id":"B53epW4XIIfi","outputId":"83e0816a-c1be-4ef7-d5ee-c2d1d9f078cf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# petal length (cm) Distribution\niris['petal length (cm)'].plot(kind='hist')\nplt.title('petal length (cm) Distribution')\nplt.xlabel('petal length (cm)')\nplt.ylabel('Frequency')\n","metadata":{"id":"Ic7aKESPIT4S","outputId":"a0adea54-7297-49a3-e50a-27c9e702f5e6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#petal width (cm) Distribution\niris['petal width (cm)'].plot(kind='hist')\nplt.title('petal width (cm) Distribution')\nplt.xlabel('petal width (cm)')\nplt.ylabel('Frequency')","metadata":{"id":"c-B5q3ZiIY5g","outputId":"0a6fc584-13bc-4065-cc85-ee9301857ec3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris.plot(kind=\"scatter\", x=\"petal length (cm)\", y=\"petal width (cm)\")","metadata":{"id":"rr_3viGwIdsv","outputId":"9814aae6-5d4a-41cc-98ed-08593d4af304"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.FacetGrid(iris, hue=\"species\", size=5) \\\n   .map(plt.scatter, \"petal length (cm)\", \"petal width (cm)\") \\\n   .add_legend()\n","metadata":{"id":"DXKGMxIhIhgB","outputId":"9429971a-41cf-4ff0-a39f-096b780d201b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.boxplot(x=\"species\", y=\"petal length (cm)\", data=iris)\nax = sns.stripplot(x=\"species\", y=\"petal length (cm)\", data=iris, jitter=True, edgecolor=\"gray\")\n","metadata":{"id":"NuVM-aSFIoFB","outputId":"0e253bfe-8f86-4d2f-d9b9-71f9b1ee81cc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Split Data","metadata":{"id":"6_gKbVkDiIbR"}},{"cell_type":"code","source":"# Function to split train & test & validate\ndef train_validate_test_split(data, labels, testRatio=0.3, valRatio=0.3):\n  \"\"\"\n  Inputs:\n  data(numpy array)\n  labels (numpy array)\n  testRatio (Float)\n  valRatio (Float)\n  Outputs:\n  X_train (numpy array)\n  X_val (numpy array)\n  X_test (numpy array)\n  y_train (numpy array)\n  y_val (numpy array)\n  y_test (numpy array)\n\n  \n  \"\"\"\n  # Data size\n  n = len(data)\n  val_n = int(valRatio*n)\n  test_n = int(testRatio*n)\n  train_n = n-val_n-test_n # do not do `int((1-valRatio-testRatio)*n)` since rows might go missing when converting to int\n\n  # # Shuffle indices and data\n  np.random.seed(5) # set seed to keep randomness constant each run\n  idx = np.arange(n)\n  np.random.shuffle(idx)\n\n  X, y = data[idx], labels[idx]\n\n  # Split the data\n  # Train\n  X_train, y_train = X[:train_n], y[:train_n]\n  # Validation\n  X_val, y_val = X[train_n : train_n+val_n], y[train_n : train_n+val_n]\n  # Test\n  X_test, y_test = X[train_n+val_n:], y[train_n+val_n:]\n\n  return X_train, X_val, X_test, y_train, y_val, y_test","metadata":{"id":"rVPRzX6BsKAa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = iris.iloc[:,:-1].to_numpy()\ny = iris.species.to_numpy()\n\nX_train, X_val, X_test, y_train, y_val, y_test = train_validate_test_split(X,y,0.3,0.3)\n\nprint(f'Train X: {len(X_train)}, Train y: {len(y_train)}')\nprint(f'Val X: {len(X_val)}, Val y: {len(y_val)}')\nprint(f'Test X: {len(X_test)}, Test y: {len(y_test)}')\n\nprint(f'Total: {len(X_train)+len(X_val)+len(X_test)}')","metadata":{"id":"ghELf9cs4eGt","outputId":"0a6950fc-71c0-48b0-bad2-c77a21ddee28"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Accuracy Function","metadata":{"id":"49uI9y79uQqM"}},{"cell_type":"code","source":"# Function to calculate accuracy\ndef calculate_accuracy(y_actual, y_pred):\n  return sum(y_actual == y_pred)/len(y_actual) ","metadata":{"id":"uRNIFaeF8YFD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Train - Bayes Classifier\n","metadata":{"id":"8G5V3h9g_Nuq"}},{"cell_type":"markdown","source":"## 5.1. Gaussian Naive Bayes","metadata":{"id":"IT6zfyqfh_MP"}},{"cell_type":"markdown","source":"**Gaussian Naive Bayes**\n\n(Gaussian) Naive Bayes assumes that each class follow a Gaussian distribution.\n\n## <center> $P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}\\right)$","metadata":{"id":"jz0x0eNCBW9N"}},{"cell_type":"code","source":"# Model Training\nGNBclf = GaussianNB()\nGNBmodel = GNBclf.fit(X_train, y_train)\n# Model Prediction\nGNB_pred = GNBclf.predict(X_val)\n\n# Model Accuracy\nGNB_acc = calculate_accuracy(y_val, GNB_pred)\nprint('Gaussian Naive Bayes accuracy score: {0:0.4f}'. format(GNB_acc))\nprint(classification_report(y_val, GNB_pred))","metadata":{"id":"tPWSX_FiDq28","outputId":"633f4d14-478b-4945-fa74-e92ab89a322a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating  a confusion matrix,which compares the y_test and y_pred\ncm = confusion_matrix(y_val, GNB_pred)\n# Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.\ncm_df = pd.DataFrame(cm,\n                     index = ['Setosa (0)','Versicolour (1)','Virginica (2)'], \n                     columns = ['Setosa (0)','Versicolour (1)','Virginica (2)'])\n#Plotting the confusion matrix\nplt.figure(figsize=(8,5))\nsns.heatmap(cm_df, annot=True)   \nplt.title('Confusion Matrix')\nplt.ylabel('ACTUAL VALUES')\nplt.xlabel('PREDICTED VALUES')\nplt.show()","metadata":{"id":"Spg9C7kh4Kfx","outputId":"4e0a4bbf-210e-460a-b7e4-8c8070d879a0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2. Multinomial Naive Bayes","metadata":{"id":"hPj2BKlqitlO"}},{"cell_type":"markdown","source":"implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification (where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice). The distribution is parametrized by vectors  for each class , where  is the number of features (in text classification, the size of the vocabulary) and  is the probability  of feature  appearing in a sample belonging to class .\n\nThe parameters  is estimated by a smoothed version of maximum likelihood, i.e. relative frequency counting:\n## <center> $\\hat{\\theta}_{yi} = \\frac{ N_{yi} + \\alpha}{N_y + \\alpha n}$","metadata":{"id":"cVgxjC3MRNXw"}},{"cell_type":"code","source":"# Model Training\nMulticlf = MultinomialNB()\nMultimodel = Multiclf.fit(X_train, y_train)\n# Model Prediction\nMulti_pred = Multimodel.predict(X_val)\n# Model Accuracy\nMulti_acc = calculate_accuracy(y_val, Multi_pred)\nprint('Multinomial Naive Bayes accuracy score: {0:0.4f}'.format(Multi_acc))\nprint(classification_report(y_val, Multi_pred))","metadata":{"id":"uMneXFEvis9n","outputId":"0d367e6f-472b-41ca-e69c-b55da5cfab44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating  a confusion matrix,which compares the y_test and y_pred\ncm = confusion_matrix(y_val, Multi_pred)\n# Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.\ncm_df = pd.DataFrame(cm,\n                     index = ['Setosa (0)','Versicolour (1)','Virginica (2)'], \n                     columns = ['Setosa (0)','Versicolour (1)','Virginica (2)'])\n#Plotting the confusion matrix\nplt.figure(figsize=(8,5))\nsns.heatmap(cm_df, annot=True)   \nplt.title('Confusion Matrix')\nplt.ylabel('ACTUAL VALUES')\nplt.xlabel('PREDICTED VALUES')\nplt.show()","metadata":{"id":"T5QgLbuboEqX","outputId":"789af56b-7ec8-4868-b466-4c4768e0a5ec"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3. Complement Naive Bayes","metadata":{"id":"ZRldNgLGqC2T"}},{"cell_type":"markdown","source":" implements the complement naive Bayes (CNB) algorithm. CNB is an adaptation of the standard multinomial naive Bayes (MNB) algorithm that is particularly suited for imbalanced data sets. Specifically, CNB uses statistics from the complement of each class to compute the model’s weights. The inventors of CNB show empirically that the parameter estimates for CNB are more stable than those for MNB. Further, CNB regularly outperforms MNB (often by a considerable margin) on text classification tasks. The procedure for calculating the weights is as follows:\n ## <center> $\\begin{align}\\begin{aligned}\\hat{\\theta}_{ci} = \\frac{\\alpha_i + \\sum_{j:y_j \\neq c} d_{ij}} {\\alpha + \\sum_{j:y_j \\neq c} \\sum_{k} d_{kj}}\\\\w_{ci} = \\log \\hat{\\theta}_{ci}\\\\w_{ci} = \\frac{w_{ci}}{\\sum_{j} |w_{cj}|}\\end{aligned}\\end{align}$","metadata":{"id":"P9Xa-nXhRreQ"}},{"cell_type":"code","source":"# Model Training\nCompclf = ComplementNB()\nCompmodel = Compclf.fit(X_train, y_train)\n# Model Prediction\nComp_pred = Compmodel.predict(X_val)\n# Model Accuracy\nComp_acc = calculate_accuracy(y_val, Comp_pred)\nprint('Complement Naive Bayes accuracy score: {0:0.4f}'.format(Comp_acc))\nprint(classification_report(y_val, Comp_pred))","metadata":{"outputId":"7dc3b47f-b6cc-42b7-e901-3f6655fc3d5f","id":"3lLJd9lVqIWH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating  a confusion matrix,which compares the y_test and y_pred\ncm = confusion_matrix(y_val, Comp_pred)\n# Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.\ncm_df = pd.DataFrame(cm,\n                     index = ['Setosa (0)','Versicolour (1)','Virginica (2)'], \n                     columns = ['Setosa (0)','Versicolour (1)','Virginica (2)'])\n#Plotting the confusion matrix\nplt.figure(figsize=(8,5))\nsns.heatmap(cm_df, annot=True)   \nplt.title('Confusion Matrix')\nplt.ylabel('ACTUAL VALUES')\nplt.xlabel('PREDICTED VALUES')\nplt.show()","metadata":{"id":"nQoPii1PqIWL","outputId":"62b531aa-98ed-4acf-a61b-587cb341d17b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.4. Bernoulli Naive Bayes","metadata":{"id":"OVyJiRxcrNzt"}},{"cell_type":"markdown","source":"implements the naive Bayes training and classification algorithms for data that is distributed according to multivariate Bernoulli distributions; i.e., there may be multiple features but each one is assumed to be a binary-valued (Bernoulli, boolean) variable. Therefore, this class requires samples to be represented as binary-valued feature vectors; if handed any other kind of data, a BernoulliNB instance may binarize its input (depending on the binarize parameter).\n\nThe decision rule for Bernoulli naive Bayes is based on\n## <center> $P(x_i \\mid y) = P(x_i = 1 \\mid y) x_i + (1 - P(x_i = 1 \\mid y)) (1 - x_i)$","metadata":{"id":"qpdSNf-vSKIj"}},{"cell_type":"code","source":"# Model Training\nBernclf = BernoulliNB()\nBernmodel = Bernclf.fit(X_train, y_train)\n# Model Prediction\nBern_pred = Bernmodel.predict(X_val)\n# Model Accuracy\nBern_acc = calculate_accuracy(y_val, Bern_pred)\nprint('Bernoulli Naive Bayes accuracy score: {0:0.4f}'.format(Bern_acc))\nprint(classification_report(y_val, Bern_pred))","metadata":{"outputId":"79fca8a9-6d00-4a0f-9c50-c6d57162412a","id":"hZMiag9krbYn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating  a confusion matrix,which compares the y_test and y_pred\ncm = confusion_matrix(y_val, Bern_pred)\n# Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.\ncm_df = pd.DataFrame(cm,\n                     index = ['Setosa (0)','Versicolour (1)','Virginica (2)'], \n                     columns = ['Setosa (0)','Versicolour (1)','Virginica (2)'])\n#Plotting the confusion matrix\nplt.figure(figsize=(8,5))\nsns.heatmap(cm_df, annot=True)   \nplt.title('Confusion Matrix')\nplt.ylabel('ACTUAL VALUES')\nplt.xlabel('PREDICTED VALUES')\nplt.show()","metadata":{"outputId":"7481955e-2d7c-4569-ec89-6b2df15995d6","id":"NCNe0SLorbYo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Decision Boundary","metadata":{"id":"DuqXk2F5CYH_"}},{"cell_type":"markdown","source":"## 2-D","metadata":{"id":"6zqB0VV8_t8h"}},{"cell_type":"code","source":"#Draw decision boundaries\nX_decision = X_train[:, [0, 2]]\n\n\n# Training a classifier\nGNBclf_D = GaussianNB()\nGNBmodel_D = GNBclf_D.fit(X_decision, y_train)\nGNBmodel_D\n\n# Plotting decision regions\nplot_decision_regions(X_decision, y_train, clf=GNBclf_D, legend=2)\n\n# Adding axes annotations\nplt.xlabel('sepal length [cm]')\nplt.ylabel('petal length [cm]')\nplt.title('GNBclf on Iris')\nplt.show()\n","metadata":{"id":"VCBNZ8o7JELZ","outputId":"487f0a0e-0999-4fdc-8bd9-9ab5cc58d76c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Draw decision boundaries\nX_decision = X_train[:, [0, 2]]\n\n\n# Training a classifier\nMulticlf_D =  MultinomialNB()\nMultimodel_D = Multiclf_D.fit(X_decision, y_train)\nMultimodel_D\n\n# Plotting decision regions\nplot_decision_regions(X_decision, y_train, clf=Multiclf_D , legend=2)\n\n# Adding axes annotations\nplt.xlabel('sepal length [cm]')\nplt.ylabel('petal length [cm]')\nplt.title('Multiclf on Iris')\nplt.show()\n","metadata":{"id":"KdKTo6VKM4bV","outputId":"1bd13524-62ba-4d40-8865-ab566af9ccf9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Draw decision boundaries\nX_decision = X_train[:, [0, 2]]\n\n\n# Training a classifier\nCompclf_D = ComplementNB()\nCompmodel_D = Compclf_D.fit(X_decision, y_train)\nCompmodel_D\n\n# Plotting decision regions\nplot_decision_regions(X_decision, y_train, clf=Compclf_D , legend=2)\n\n# Adding axes annotations\nplt.xlabel('sepal length [cm]')\nplt.ylabel('petal length [cm]')\nplt.title('Compclf on Iris')\nplt.show()\n","metadata":{"id":"KMoQyy4qOKK7","outputId":"7b958078-ac11-4835-82ee-4a9e6fdf43a7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Draw decision boundaries\nX_decision = X_train[:, [0, 2]]\n\n\n# Training a classifier\nBernclf_D = BernoulliNB()\nBernmodel_D = Bernclf_D.fit(X_decision, y_train)\nBernmodel_D\n\n# Plotting decision regions\nplot_decision_regions(X_decision, y_train, clf=Bernclf_D  , legend=2)\n\n# Adding axes annotations\nplt.xlabel('sepal length [cm]')\nplt.ylabel('petal length [cm]')\nplt.title('Bernclf on Iris')\nplt.show()\n","metadata":{"id":"O_qfRidbOw9X","outputId":"f1e0eacf-5a86-45cb-f717-32633010f006"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-D","metadata":{"id":"UymZ8nmbTF1U"}},{"cell_type":"markdown","source":"### All data","metadata":{"id":"-9OEkJVfFNg0"}},{"cell_type":"code","source":"from plotly.express import scatter_3d\n# Plotting in 3D by plotly.express that would show the plot with capability of zooming,\n# changing the orientation, and rotating\nscatter_3d(iris, x='sepal length (cm)', y='sepal width (cm)', z='petal length (cm)', size=\"petal width (cm)\",\n                   color=\"species\", color_discrete_map={\"Joly\": \"blue\", \"Bergeron\": \"violet\", \"Coderre\": \"pink\"})\\\n            .show()","metadata":{"id":"oZjXu3OOHQqa","outputId":"2b56ad59-38ca-409e-89a7-a56375b95fb1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model predictions","metadata":{"id":"dqLuZX9nFRdy"}},{"cell_type":"markdown","source":"#### Gaussian","metadata":{"id":"d3B8NJUPFzKa"}},{"cell_type":"code","source":"scatter_3d(x=X_val[:, :1].flatten(), \n           y=X_val[:, 1:2].flatten(), \n           z=X_val[:, 2:3].flatten(), \n           size=X_val[:, 3:4].flatten(),\n           color=GNB_pred.flatten(), \n           color_discrete_map={\"Joly\": \"blue\", \"Bergeron\": \"violet\", \"Coderre\": \"pink\"},\n           labels={'x':'Sepal length (cm)', 'y':'Sepal width (cm)', 'z':'Petal length (cm)', 'size':'Petal width (cm)','color':'Species'})\\\n            .show()","metadata":{"id":"Qme8Zg4GF0lE","outputId":"a0229365-e57c-4df0-83e4-86aa5f8acba4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Multinomial","metadata":{"id":"OPgn26cfGUfz"}},{"cell_type":"code","source":"scatter_3d(x=X_val[:, :1].flatten(), \n           y=X_val[:, 1:2].flatten(), \n           z=X_val[:, 2:3].flatten(), \n           size=X_val[:, 3:4].flatten(),\n           color=Multi_pred.flatten(), \n           color_discrete_map={\"Joly\": \"blue\", \"Bergeron\": \"violet\", \"Coderre\": \"pink\"},\n           labels={'x':'Sepal length (cm)', 'y':'Sepal width (cm)', 'z':'Petal length (cm)', 'size':'Petal width (cm)','color':'Species'})\\\n            .show()","metadata":{"id":"isOYS2EpGeAZ","outputId":"c54cc40f-f494-453a-97d8-ac485af07986"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Complement","metadata":{"id":"JJDl5DvbGWcT"}},{"cell_type":"code","source":"scatter_3d(x=X_val[:, :1].flatten(), \n           y=X_val[:, 1:2].flatten(), \n           z=X_val[:, 2:3].flatten(), \n           size=X_val[:, 3:4].flatten(),\n           color=Comp_pred.flatten(), \n           color_discrete_map={\"Joly\": \"blue\", \"Bergeron\": \"violet\", \"Coderre\": \"pink\"},\n           labels={'x':'Sepal length (cm)', 'y':'Sepal width (cm)', 'z':'Petal length (cm)', 'size':'Petal width (cm)','color':'Species'})\\\n            .show()","metadata":{"id":"pIvLn5j3GfQW","outputId":"1a8b4297-506e-4068-ed7e-a9deb708a6a4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Bernoulli","metadata":{"id":"Jtt_iEhAGYJs"}},{"cell_type":"code","source":"scatter_3d(x=X_val[:, :1].flatten(), \n           y=X_val[:, 1:2].flatten(), \n           z=X_val[:, 2:3].flatten(), \n           size=X_val[:, 3:4].flatten(),\n           color=Bern_pred.flatten(), \n           color_discrete_map={\"Joly\": \"blue\", \"Bergeron\": \"violet\", \"Coderre\": \"pink\"},\n           labels={'x':'Sepal length (cm)', 'y':'Sepal width (cm)', 'z':'Petal length (cm)', 'size':'Petal width (cm)','color':'Species'})\\\n            .show()","metadata":{"id":"166zLmKzGgm7","outputId":"9e0bb475-ce7a-492d-f75c-bdf4919c3cd2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Models Comparison","metadata":{"id":"MsUxY8oDnYxN"}},{"cell_type":"code","source":"models = ['Gaussian', 'Multinomial', 'Complement', 'Bernoulli']\naccuracies = [GNB_acc, Multi_acc, Comp_acc, Bern_acc]\n\nfor model, accuracy in zip(models, accuracies):\n  print(model)\n  print(round(accuracy,2))\n  print('----------------')","metadata":{"id":"eMIjxPgD81d1","outputId":"f6ac7f79-b57b-464a-f41d-371710c6cd66"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nax = sns.barplot(x = models, y = accuracies)\n\nplt.xlabel('Models')\nplt.ylabel('Accuracy')\nplt.title('Comparing Accuracy of Models');","metadata":{"id":"zrzAKJHFj_97","outputId":"dbb636ac-f0f8-4ca6-e977-03270d99f1a8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Therefore, `Gaussian Naive Bayes` is the best model with `0.93 accuracy`","metadata":{"id":"yDbaNv-7EjU5"}},{"cell_type":"code","source":"# Model Prediction on Test\nGNB_pred_test = GNBclf.predict(X_test)\n\n# Model Accuracy\nGNB_acc_test = calculate_accuracy(y_test, GNB_pred_test)\nprint('Gaussian Naive Bayes accuracy score: {0:0.4f}'. format(GNB_acc_test))\nprint(classification_report(y_test, GNB_pred_test))","metadata":{"id":"1zWDhrMDkAoc","outputId":"0a522430-a809-46b5-e764-554efc4fbe4a"},"execution_count":null,"outputs":[]}]}